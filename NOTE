# -*- coding: cp1251 -*-


 - python 3.10

 - venv3.10

 - settings - projects/python projects -  python interpr - install numpy

 - add - new venv - 3.7 - + install numpy

 - 3.10

 - file-settings - add - cvzone

 - requirements.txt - download(yt)

 - #scikit-image

 - install all requirements

 	- directory of project(running yolo)

 	- file yolo-basics

 	- directory images 3 pngs


				from ultralytics import YOLO

				import cv2



				model = YOLO('yolov8n.pt') - n or l(large)

				results = model("Images/1.png", show=True) - 1 or 2 or 3

				cv2.waitkey(0)

	- directory of project(Yolo-Weights)

	- in yolo-basics:


				from ultralytics import YOLO

				import cv2

				model = YOLO("../Yolo-Weights/yolov8n.pt")

				results = model("Images/1.png", show=True)

				cv2.waitkey(0)

	- directory of project(Yolo with Webcam)

	- file yolo-webcam

	- in yolo-webcam:

                                from ultralytics import YOLO

				import cv2

				import cvzone

				import math

				# Cap for the Webcam

				# cap = cv2.VideoCapture(1) # For Webcam or 0  (если нет то, opencv-python смотреть версию 4.5.4.60 and etc +)

				# cap.set(3, 1280)

				# cap.set(4, 720)


				# Cap for the Video

				cap = cv2.VideoCapture("../Videos/название.mp4") # For Video



				model = YOLO("../Yolo-Weights/yolov8l.pt")  # мал/бол - n/l

				classNames = [...
					                                                       # в ролике посмотреть
					     ]


				while True:

					success, img = cap.read()

                                        results = model(img, stream=True)

					for r in results:

						boxes = r.boxes

						for box in boxes:

							# x1, y1, x2, y2 = box.xyxy[0]

							# x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)

                                                        # print(x1, y1, x2, y2)

                                                        # cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3) #3 el - colour, 4 el - thickness


							# x1, y1, w, h = box.xywh[0]

							# bbox = int(x1), int(y1), int(w), int(h)

							# print(x1, y1, w, h)

							# cvzone.cornerRect(img, bbox)


							# Bounding Box

							x1, y1, x2, y2 = box.xyxy[0]

							x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)

							w, h = x2 - x1, y2 - y1

							cvzone.cornerRect(img, (x1, y1, w, h)) # - посмотреть в функкции аргументы - цвет и т.п

                                                        # Confidence

							conf = math.ceil((box.conf[0] * 100)) / 100 # - rounded # - возможно лишние скобки

							# cvzone.putTextRect(img, f'{conf}, (max(0, x1), max(35, y1))) - снизу дополнен


							# Class Name

							cls = int(box.cls[0])


							cvzone.putTextRect(img, f'{classNames[cls]} {conf}', (max(0, x1), max(35, y1)), scale=1, thickness=1)




					cv2.imshow("Image", img)

					cv2.waitKey(1)

				results = model("Images/1.png", show=True)

				cv2.waitkey(0)


	- directory of project(Videos)

	- найти видео рандомные

 - GPU

 - install Visual Studio - community version - + Desktop development with C++

 - что-то с драйверами(1:10:00)

 - install cuda Toolkit 12.0 Update

 - In program files - Nvidia GPU Computing lookit - Cuda - > v11.5 - bin - install

 - install Nvidia cuDNN - version of cuDNN = Cuda

 - Drop all in bin cuDNN to bin CUDA and in include cuDNN to include CUDA and in lib cuDNN to lib - x64 CUDA

 - control panel - system environment variables - Environmet Variables - variable(CUDA_PATH_V11_5) > GPU_Computing_Toolkit\\CUDA\v11.5

 - go to PyTorch - install(pytorch.org/get-started/locally/) - stable/win/pip/python/cuda 11.6 - copy command - terminal - command prompt(not local) - paste

 - if it install again run Yolo-Webcam and guve CPU - перед этим чекнуть - file - settings - python interp - torch + torchaodio + torchvision(unistall all) - go terminal - run command again (верхнюю)

 - again run Yolo-Webcam (see Cuda an etc)



!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
 - New project Car Counter - copy Yolo-Webcam (Car Counter) - все верхние кэпы удалить - и в последнем поменять на cars.mp4


							cvzone.cornerRect(img, (x1, y1, w, h), l=15) # or 5/10 and etc

							cvzone.putTextRect(img, f'{classNames[cls]} {conf}', (max(0, x1), max(35, y1)), scale=0.6, thickness=1, offset=5) # можно через цикл прогонять файлы мп4 и выставлять значения функции фикнесса и т.п. под видео

							#Перед тем что сверху пишем класс - для распознания не просто машин - а автобус, мотоцикл и т.п. (меняем classNames[cls] на currentClass)

							currentClass = classNames[cls]

							if currentClass == "car" or currentClass == "truck" or currentClass == "bus" or currentClass == "motorbike" #or currentClass == "motorbike" and conf > 0.3:

								#cvzone.putTextRect(img, f'{currentClass} {conf}', (max(0, x1), max(35, y1)), scale=0.6, thickness=1, offset=5)

								 - удалить cvzone.cornerRect(img, (x1, y1, w, h), l=15) # or 5/10 and etc и кинуть в этот цикл

								cvzone.cornerRect(img, (x1, y1, w, h), l=) # or 5/10 and etc




					cv2.imshow("Image", img)

					cv2.waitKey(0)



 - чтобы ловить машины которые едут в определенном рентагле go to canva.com

 - press r - give rentagle

 - c 1:35:50 watch - все сделать

 - как все сделали share - download - throw to project Car Counter and save name Mask

 - далее в коде пишем, после сласснамс(список):


 			mask = cv2.imread("Mask.png)


			# В цикле вайл: после саксесс:

			imgRegion = cv2.bitwise_and(img, mask)

			results = model(imgRegion, stream=True)



					cv2.imshow("Image", img)

					cv2.imshow("ImageRegion", imgRegion)

					cv2.waitKey(0)


 - #count cars

 - #Перейти на гит парня (1:43:00) скачать - sort.py and copy it to project Car Counter / чекнуть в requirments все ли есть в нашем проекте (эти библиотеки)

 - #В Car Counter пишем:

			from sort import *  #at the begging

			#после mask и перед циклом:


			#Sort tracking

			tracker = Sort(max_age=20, min_units=3, iou_threshold=0.3)

			limits = [400, 297, 673, 297]



			# В цикле вайл: после саксесс:

			results = model(imgRegion, stream=True)

			detections = np.empty((0, 5))



			#В условии if после свзонекорнеррект(его потом закомментировать)

			currentArray = np.array([x1, y1, x2, y2, conf])

			detections = np.vstack((detecions, currentArray))



		resultsTracker = tracker.update(detections)

		cv2.line(img, (limits[0], limits[1]), (limits[2], limits[3]), (0, 0, 255), 5)

		for result in resultsTracker:

			x1, y1, x2, y2, id = result

			x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)

			print(result)

			w, h = x2 - x1, y2 - y1

			cvzone.cornerRect(img, (x1, y1, w, h), l=9, rt=2, colorR=(255, 0, 255))

			cvzone.putTextRect(img, f'{int(id)}', (max(0, x1), max(35, y1)), scale=2, thickness=3, offset=10)


			(У него cx and cy) centerX, centerY = x1 + w // 2, y1 = y1 + h//2

			cv2.circle(img, (centerX, centerY), 5, (255, 0, 255), cv2.FILLED)

			if limits[0] < centerX < limits[2] and limits[1] - 15 < centerY < limits[1] + 15:

- после limits (list'a): write: totalCount = []

	(в этом условии пишем) if totalCount.count(id) == 0:

					totalCount.append(id)

					cv2.line(img, (limits[0], limits[1]), (limits[2], limits[3]), (0, 255, 0), 5)


		# cvzone.putTextRect(img, f' Count: {len(totalCount)}', (50, 50))

		cv2.putText(img, str(len(totalCount)), (255, 100, 0), cv2.FONT_HERSHEY_PLAIN, 5, (50, 50, 255), 8)

		cv2.imshow("Image", img)

		# cv2.imshow("ImageRegion", imgRegion)

		cv2.waitKey(1) #0


	- в проект закидываем файл grapics.png (взять у него из ролика)


	- в цикл while true после imgRegion:

		imgRegion = cv2.imread("graphics.png", cv2.IMREAD_UNCHANGED)

		img = cvzone.overlayPNG(img, imgRegion, (0, 0))



 - New project People Counter

	- коппируем папку с кар-коунтер и переименовываем все для пипл.

	- меняем ссылку на видео в переменной cap

	- взять файл gtaphics из видео


	- в цикле while true после imgRegion:

		imgRegion = cv2.imread("graphics.png", cv2.IMREAD_UNCHANGED)

		img = cvzone.overlayPNG(img, imgRegion, (0, 0))

		# меняем на:

		imgRegion = cv2.imread("graphics.png", cv2.IMREAD_UNCHANGED)

		img = cvzone.overlayPNG(img, imgRegion, (730, 260))


		# затем	меняем:

					if currentClass == "car" or currentClass == "truck" or currentClass == "bus" or currentClass == "motorbike" #or currentClass == "motorbike" and conf > 0.3:



		# На:

					if currentClass == "person" and conf > 0.3:


		# Создадим маску такую же как и для машин и ее вложить в папку проекта (People Counter)

		# открываем имджрегион

		cv2.imshow("Image", img)

		cv2.imshow("ImageRegion", imgRegion)

		cv2.waitKey(1) #0

		# Вместо limits, сделаем 2 лимита для тех, кто поднимается и для тех, кто опускается:


			limitsUp = [103, 161, 296, 161]

			limitsDown = [527, 489, 735, 489]


		# После этого указываем:

		totalCountUp = []

		totalCountDown = []

		# выше забыли:


		cv2.line(img, (limits[0], limits[1]), (limits[2], limits[3]), (0, 0, 255), 5)

			# меняем на:

		cv2.line(img, (limitsUp[0], limitsUp[1]), (limitsUp[2], limitsUp[3]), (0, 0, 255), 5)

		cv2.line(img, (limitsDown[0], limitsDown[1]), (limitsDown[2], limitsDown[3]), (0, 0, 255), 5)

		# again change


				if limitsUp[0] < centerX < limitsUp[2] and limitsUp[1] - 15 < centerY < limitsUp[1] + 15:

				(в этом условии пишем) if totalCountUp.count(id) == 0:

						totalCountUp.append(id)

						cv2.line(img, (limitsUp[0], limitsUp[1]), (limitsUp[2], limitsUp[3]), (0, 255, 0), 5)


				# cvzone.putTextRect(img, f' Count: {len(totalCount)}', (50, 50))

				cv2.putText(img, str(len(totalCountUp)), (929, 345, 0), cv2.FONT_HERSHEY_PLAIN, 5, (139, 195, 74), 7)

		# add for down


				if limitsDown[0] < centerX < limitsDown[2] and limitsDown[1] - 15 < centerY < limitsDown[1] + 15:

				(в этом условии пишем) if totalCountDown.count(id) == 0:

						totalCountDown.append(id)

						cv2.line(img, limitsDown[0], limitsDown[1]), limitsDown[2], limitsDown[3]), (0, 255, 0), 5)


				# cvzone.putTextRect(img, f' Count: {len(totalCount)}', (50, 50))

				cv2.putText(img, str(len(totalCountDown)), (1191, 345, 0), cv2.FONT_HERSHEY_PLAIN, 5, (50, 50, 230), 7)



 - #Продолжать с 2:32:00